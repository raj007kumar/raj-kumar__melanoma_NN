{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye26PBChjs95"
      },
      "source": [
        "Importing all the important libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jCe2oD1YI4am"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SnSrhpVtK7JM",
        "outputId": "25846cae-d4f9-446d-89e4-743c2ae0837f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\",force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHGxfUGxV791"
      },
      "source": [
        "This assignment uses a dataset of about 2357 images of skin cancer types. The dataset contains 9 sub-directories in each train and test subdirectories. The 9 sub-directories contains the images of 9 skin cancer types respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SUWQuFSuV_X8"
      },
      "outputs": [],
      "source": [
        "# Defining the path for train and test images\n",
        "## Updating the paths of the train and test dataset\n",
        "data_dir_train = pathlib.Path(\"/content/gdrive/MyDrive/Skin cancer ISIC The International Skin Imaging Collaboration/Train\")\n",
        "data_dir_test = pathlib.Path('/content/gdrive/MyDrive/Skin cancer ISIC The International Skin Imaging Collaboration/Test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oj05iiZOZOKe"
      },
      "outputs": [],
      "source": [
        "## Looking at the the list of files in the directory\n",
        "#!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MQ46fI3ZRSr"
      },
      "outputs": [],
      "source": [
        "## Checking the image count in train and test data sets\n",
        "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
        "print(image_count_train)\n",
        "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
        "print(image_count_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar5kHActZ6T9"
      },
      "source": [
        "#### Load using keras.preprocessing\n",
        "\n",
        "#### Let's load these images off disk using the helpful image_dataset_from_directory utility."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acZKcEreZ2pB"
      },
      "source": [
        "### Create a dataset\n",
        "\n",
        "Define some parameters for the loader:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiJwL9-uZq03"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHSJ8FtIaG8a"
      },
      "source": [
        "Use 80% of the images for training, and 20% for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5dRH1j0aBot"
      },
      "outputs": [],
      "source": [
        "## Writing the train dataset \n",
        "##  used seed=123 while creating dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
        "##  resizing images to the size img_height*img_width\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = 'training',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwaG0szcaNQJ"
      },
      "outputs": [],
      "source": [
        "## checking the validation dataset\n",
        "## used seed=123 while creating the dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
        "## Resized images to the size img_height*img_width\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = 'validation',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Kx4Y_AdaTac"
      },
      "outputs": [],
      "source": [
        "# Listing out all the classes of skin cancer and storing them in a list. \n",
        "# Checking the class names in the class_names attribute on these datasets. \n",
        "# These correspond to the directory names in alphabetical order.\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKWiByFIakNZ"
      },
      "source": [
        "### Visualize the data\n",
        "#### Visualize one instance of all the nine classes present in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMRVbctWabA1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "### your code goes here, you can use training or validation data to visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDkuqCQCa2Yc"
      },
      "source": [
        "The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3RlbXJCKYgL"
      },
      "outputs": [],
      "source": [
        "def class_distribution_count(directory):\n",
        "    \n",
        "    #count number of image in each classes\n",
        "    count= []\n",
        "    for path in pathlib.Path(directory).iterdir():\n",
        "        if path.is_dir():\n",
        "            count.append(len([name for name in os.listdir(path)\n",
        "                               if os.path.isfile(os.path.join(path, name))]))\n",
        "    \n",
        "    #name of the classes\n",
        "    sub_directory = [name for name in os.listdir(directory)\n",
        "                    if os.path.isdir(os.path.join(directory, name))]\n",
        "    \n",
        "    #return dataframe with image count and class.\n",
        "    return pd.DataFrame(list(zip(sub_directory,count)),columns =['Class', 'No. of Image'])\n",
        "\n",
        "df = class_distribution_count(data_dir_train)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvPJfegCKssE"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x=\"No. of Image\", y=\"Class\", data=df,\n",
        "            label=\"Class\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7pVBR2Qa4ii"
      },
      "source": [
        "`Dataset.cache()` keeps the images in memory after they're loaded off disk during the first epoch.\n",
        "\n",
        "`Dataset.prefetch()` overlaps data preprocessing and model execution while training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbgPqvT3apBy"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVS_K1DIc4PR"
      },
      "source": [
        "###Create the model\n",
        "\n",
        "#### Creating a CNN model, which can accurately detect 9 classes present in the dataset. Use layers.experimental.preprocessing.Rescaling to normalize pixel values between (0,1). The RGB channel values are in the [0, 255] range. This is not ideal for a neural network. Here, it is good to standardize values to be in the [0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9EwSHfFcuD0"
      },
      "outputs": [],
      "source": [
        "### Your code goes here\n",
        "num_classes = 9\n",
        "\n",
        "model = Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhLc-p0RdfyD"
      },
      "source": [
        "### Compile the model\n",
        "Choose an appropirate optimiser and loss function for model training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kL9ZH2ldRpa"
      },
      "outputs": [],
      "source": [
        "### choose Sparse Categorical Crossentropy optimiser and relu loss function\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIQgAZn0dj_i"
      },
      "outputs": [],
      "source": [
        "# View the summary of all layers\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEPJCUMzdyUf"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjynkmRodq5u"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB4tXVtPeQH7"
      },
      "source": [
        "### Visualizing training results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QLrg6sId1d0"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZAxep-tDR_z"
      },
      "outputs": [],
      "source": [
        "# Lets store the final accuracy in a dataframe for the consecutive training\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "accuracy_history_df = pd.DataFrame(data=[{\"Type\":\"Vanilla\",\"Training Accuracy\":acc[-1],\"Validation Accuracy\":val_acc[-1],\"Epochs\":epochs}])\n",
        "accuracy_history_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBF-D9-GegdE"
      },
      "source": [
        "#### Todo: Write your findings after the model fit, see if there is an evidence of model overfit or underfit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q55Q7kEPeitC"
      },
      "source": [
        "## Clearly the modelis underfitting as validation loss is too high when compared with training loss resulting in poor validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6VJ4Kr-eUQt"
      },
      "outputs": [],
      "source": [
        "# data augumentation by flipping the images horizontally. \n",
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                 input_shape=(img_height, \n",
        "                                                              img_width,\n",
        "                                                              3)),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37ZATL-XfLqo"
      },
      "outputs": [],
      "source": [
        "# Visualize augmentation strategy works for one instance of training image.\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrzl2QfGf90U"
      },
      "source": [
        "##### Create the model, compile and train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vK6gCcEpfQIt"
      },
      "outputs": [],
      "source": [
        "## Dropout layer introduced to tackle overfitting\n",
        "\n",
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oabloRGWgJcU"
      },
      "source": [
        "### Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kx4TAcq0gCSN"
      },
      "outputs": [],
      "source": [
        "## Your code goes here\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs-8E3lSgRVC"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hDJcg25gM90"
      },
      "outputs": [],
      "source": [
        "## Training the model for 20 epochs\n",
        "epochs = 20\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK06t_5ug04G"
      },
      "source": [
        "### Visualizing the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HsAitdCgU9f"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuZ_mXhmDJM9"
      },
      "outputs": [],
      "source": [
        "# Lets store the final accuracy in a dataframe for the consecutive training\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "accuracy_history_df = pd.DataFrame(data=[{\"Type\":\"Vanilla\",\"Training Accuracy\":acc[-1],\"Validation Accuracy\":val_acc[-1],\"Epochs\":epochs}])\n",
        "accuracy_history_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HStNZnsehD8l"
      },
      "source": [
        "#### Todo: Write your findings after the model fit, see if there is an evidence of model overfit or underfit. Do you think there is some improvement now as compared to the previous model run?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI6tYPNbhFnk"
      },
      "source": [
        "##There is an very good improvement from the previous model but still the model can be improved as there is substantial difference in training and validation loss and accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWCQHcVGhoq5"
      },
      "source": [
        "#### **Todo:** Find the distribution of classes in the training dataset.\n",
        "#### **Context:** Many times real life datasets can have class imbalance, one class can have proportionately higher number of samples compared to the others. Class imbalance can have a detrimental effect on the final model quality. Hence as a sanity check it becomes important to check what is the distribution of classes in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gg0OAw19gy6e"
      },
      "outputs": [],
      "source": [
        "## Your code goes here.\n",
        "from glob import glob\n",
        "path_list = [x for x in glob(os.path.join(data_dir_train, '*', '*.jpg'))]\n",
        "lesion_list = [os.path.basename(os.path.dirname(y)) for y in glob(os.path.join(data_dir_train, '*', '*.jpg'))]\n",
        "len(path_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYgAS0EPh7wv"
      },
      "outputs": [],
      "source": [
        "dataframe_dict_original = dict(zip(path_list, lesion_list))\n",
        "original_df = pd.DataFrame(list(dataframe_dict_original.items()),columns = ['Path','Label'])\n",
        "original_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAsDf3pniAoy"
      },
      "outputs": [],
      "source": [
        "### Checking the distribution of all the images category wise\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import Counter\n",
        "# split into input and output elements\n",
        "X, y = original_df['Path'], original_df['Label']\n",
        "# label encode the target variable\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "# summarize distribution\n",
        "counter = Counter(y)\n",
        "for k,v in counter.items():\n",
        "\tper = v / len(y) * 100\n",
        "\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
        "# plot the distribution\n",
        "count=[]\n",
        "for i in class_names:\n",
        "    count.append(len(list(data_dir_train.glob(i+'/*.jpg'))))\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.xticks(rotation=45)\n",
        "plt.bar(class_names,count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMRMas1knd3_"
      },
      "source": [
        "- Seborrheic keratosis is having the lowest distribution\n",
        "- Pigmented Benign keratosis is having the highest distribution of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZm-xTConnKy"
      },
      "source": [
        "#### **Todo:** Rectify the class imbalance\n",
        "#### **Context:** You can use a python package known as `Augmentor` (https://augmentor.readthedocs.io/en/master/) to add more samples across all classes so that none of the classes have very few samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4Qbuz4yiGRJ"
      },
      "outputs": [],
      "source": [
        "!pip install Augmentor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucwh1OdZm5kP"
      },
      "outputs": [],
      "source": [
        "path_to_training_dataset=\"/content/gdrive/MyDrive/Skin cancer ISIC The International Skin Imaging Collaboration/Train/\"\n",
        "import Augmentor\n",
        "for i in class_names:\n",
        "    p = Augmentor.Pipeline(path_to_training_dataset + i)\n",
        "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "    p.sample(500) ## We are adding 500 samples per class to make sure that none of the classes are sparse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a53r83VgtnOT"
      },
      "source": [
        "Augmentor has stored the augmented images in the output sub-directory of each of the sub-directories of skin cancer types.. Lets take a look at total count of augmented images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0JIw6lcn9NZ"
      },
      "outputs": [],
      "source": [
        "image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))\n",
        "print(image_count_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voPxcSUStvIf"
      },
      "source": [
        "### Lets see the distribution of augmented data after adding new images to the original training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZt4HsTqtqwz"
      },
      "outputs": [],
      "source": [
        "path_list_new = [x for x in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
        "path_list_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9c2noAEt0Hl"
      },
      "outputs": [],
      "source": [
        "lesion_list_new = [os.path.basename(os.path.dirname(os.path.dirname(y))) for y in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
        "lesion_list_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9he3v5KZt9Qh"
      },
      "outputs": [],
      "source": [
        "### Creating the new dataframe with path list and lesion list\n",
        "dataframe_dict_new = dict(zip(path_list_new, lesion_list_new))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkSE2UDPuCrS"
      },
      "outputs": [],
      "source": [
        "### Concatenating the new dataframe with columns Path and label\n",
        "df2 = pd.DataFrame(list(dataframe_dict_new.items()),columns = ['Path','Label'])\n",
        "new_df = original_df.append(df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7UHkdnBuM9Q"
      },
      "outputs": [],
      "source": [
        "new_df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4ekvmGuugoY"
      },
      "source": [
        "So, now we have added 500 images to all the classes to maintain some class balance. We can add more images as we want to improve training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKDvtgEbuoHg"
      },
      "source": [
        "#### Train the model on the data created using Augmentor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OSLmMaauQlY"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvCP0HYhu1cv"
      },
      "source": [
        "#### Create a training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eAfwb7DuuZU"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = 'training', ## Todo choose the correct parameter value, so that only training data is refered to\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdXo4sdwvKi-"
      },
      "source": [
        "### Create a validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BawJxG3Su_fo"
      },
      "outputs": [],
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = 'validation',## Todo choose the correct parameter value, so that only validation data is refered to,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Il6BjIew0zQy"
      },
      "source": [
        "### Create your model (make sure to include normalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsWpms2o0so7"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "model = Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(64, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqGzQlLD1Rh9"
      },
      "source": [
        "### Compile your model (Choose optimizer and loss function appropriately)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er9AY8rA05ZF"
      },
      "outputs": [],
      "source": [
        "## your code goes here\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63Y_CE121tNJ"
      },
      "source": [
        "###  Train your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCLy5QQn1Wcb"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BagZARwP2hb6"
      },
      "source": [
        "### Visualize the model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5kdq1d91yaT"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5_G8BotIg84"
      },
      "source": [
        "Class rebalance has helped to improve the model and model is performing quite well without any overfitting and good accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Oqd-mQG2ldP"
      },
      "outputs": [],
      "source": [
        "# Lets store the final accuracy in a dataframe for the consecutive training\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "accuracy_history_df = pd.DataFrame(data=[{\"Type\":\"Vanilla\",\"Training Accuracy\":acc[-1],\"Validation Accuracy\":val_acc[-1],\"Epochs\":epochs}])\n",
        "accuracy_history_df"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}